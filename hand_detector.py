#!/usr/bin/env python
# -*- coding: utf-8 -*-

import cv2
import mediapipe as mp

# =========================================
# ğŸ§© Mediapipe ì´ˆê¸°í™”
# =========================================
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
mp_styles = mp.solutions.drawing_styles

hands = mp_hands.Hands(
    static_image_mode=False,       # ë™ì˜ìƒ ì…ë ¥
    max_num_hands=2,              # ìµœëŒ€ ì† ê°œìˆ˜
    min_detection_confidence=0.5, # íƒì§€ ì‹ ë¢°ë„
    min_tracking_confidence=0.5   # ì¶”ì  ì‹ ë¢°ë„
)

# =========================================
# ğŸ“¸ ì¹´ë©”ë¼ ì—°ê²°
# =========================================
# cap = cv2.VideoCapture(0)            # ê¸°ë³¸ ì¹´ë©”ë¼ ì‚¬ìš©ì‹œ
cap = cv2.VideoCapture("hand.mp4")   # ë™ì˜ìƒ íŒŒì¼ ì‚¬ìš© ì‹œ 

print("ğŸ“· ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‹œì‘ â€” ESCë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•©ë‹ˆë‹¤.")

while cap.isOpened():
    success, image = cap.read()
    if not success:
        print("âš ï¸ í”„ë ˆì„ì„ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”.")
        break

    # ì¢Œìš° ë°˜ì „ (ì…€ì¹´ ë·°)
    image = cv2.flip(image, 1)

    # BGR â†’ RGB ë³€í™˜
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # ì† ê²€ì¶œ ìˆ˜í–‰
    result = hands.process(image_rgb)

    # ğŸ–ï¸ ì† ëœë“œë§ˆí¬ í‘œì‹œ
    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            mp_drawing.draw_landmarks(
                image,
                hand_landmarks,
                mp_hands.HAND_CONNECTIONS,
                mp_styles.get_default_hand_landmarks_style(),
                mp_styles.get_default_hand_connections_style()
            )

    # í™”ë©´ í‘œì‹œ
    cv2.imshow('ğŸ–ï¸ MediaPipe Hand Detector', image)

    # ESC í‚¤ë¡œ ì¢…ë£Œ
    if cv2.waitKey(5) & 0xFF == 27:
        print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        break

# =========================================
# ğŸ”š ì¢…ë£Œ ì²˜ë¦¬
# =========================================
cap.release()
cv2.destroyAllWindows()
